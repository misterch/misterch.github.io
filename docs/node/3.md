---
title: 异步I/O
date: 2023-07-31

---
## 为什么要异步I/O

### 用户体验

在浏览器中，js只在单线程上执行，还**与UI渲染公用一个线程**，意味着js在执行的时候UI渲染和响应时处于停滞状态的。如果网页需要获取一个网络资源，通过同步的方式获取，那么js则需要等待资源完全从服务器端获取后才能继续执行忙着期间UI将停顿，不响应用户的交互行为。前端通过异步可以消除UI阻塞现象。

在服务端，只有快速响应资源，才能让前端的体验更好；数据分布到多台服务器上，分布式将会是常态，异步和同步在性能方面的差异会放大。I/O是昂贵的，分布式I/O更加昂贵

### 资源分配

### **单线程**

**串行**顺序依次执行，**阻塞I/O**导致硬件资源得不到更优使用

### 多线程

**并行执行**，创建线程和执行线程上下文切换的开销较大；复杂业务中，会面临**死锁，状态同步**问题；但在多核CPU上能有效**提升CPU利用率**

### node的解决方案

* 利用**单线程**，远离多线程死锁，状态同步问题
* 利用**异步I/O**，远离单线程阻塞，更好地利用CPU
* 提供类似前端Web Workers的**子进程**通过**工作进程**高效利用CPU和I/O

## 异步I/O实现现状

### 阻塞I/O

应用程序需要等待I/O完成才返回结果

阻塞I/O会造成CPU等待I/O，浪费等待时间，CPU得不到充分利用

### 异步I/O

调用后立即返回，但完整的**I/O并没有完成**

立即返回的并不是业务层期望的数据，仅仅是**当前的调用状态**

为获取完整数据，需要**重复调用I/O**，来确认是否完成

让CPU处理状态判断，是对CPU资源的浪费

* read性能低，重复调用来检查I/O状态
* select，在read基础上得到改进，通过对文件描述符上的时间状态判断；但最多同时检查1024长度的数组储存状态
* poll，改进了select，采用链表方式避免数组长度限制，避免不必要的检查，当文件描述符较多时性能还是比较低
* epoll，Linux下效率最高的I/O事件通知机制，在进入轮询的时候如果没有检查到I/O事件，将会进行休眠，直到事件发生将它唤醒；利用事件通知，执行回调，而非遍历查询，不浪费CPU
* 类似epoll，只存在FreeBSD

CPU的时间片可以用来处理其他事务，提高性能

### 现实的非阻塞异步I/O

线程池与阻塞I/O模拟异步I/O

Windows：调用异步方法，等待I/O完成后的通知，执行回调，让用户无需考虑轮询

Node：虽然js在单线程中执行，但是**node是多线程的**，内部完成I/O任务有另外的线程池；可以**实现I/O高并发**

## node的异步I/O

### 事件循环

每执行一次循环称为Tick，这个过程检查是否有事件待处理；有，取出事件及相关回调函数执行；没有，退出进程

典型的生产者/消费者模型，异步I/O，网络请求等是事件的生产者，将事件传递给观察者；事件循环从观察者中取出事件并处理

### 请求对象

从js发起调用 到 内核执行完I/O操作的过渡过程中，存在一个中间产物，就是请求对象

1. js层面调用C++核心模块
2. 核心模块调用C++内建模块
3. 内建模块通过libuv进行系统调用
4. libuv作为封装层，有两个平台的实现；
5. 将对象推入线程池中等待执行

:::tip

在线程池中等待执行的I/O操作不管是否阻塞I/O，js线程可以继续执行后续操作

:::

## 非I/O的异步API

事件循环对观察者的检查优先级：idle>I/O>check

### 定时器

> 宏任务



:::tip

只能控制何时放入队列中，不能控制何时执行

:::

setTimeout

setInterval

### precess.nextTick

> 微任务
>
> idle观察者

比setTimeout轻量，高性能

只将回调函数放进队列中，下一轮Tick取出执行

结果保存在一个数组中，每轮循环将数组中的**回调函数全部执行完**

### setImmediate

> check观察者

结果保存在链表中，每轮循环执行链表中的**一个回调函数**，保证每轮循环能够较快执行结束，防止CPU占用过多而阻塞后续I/O调用


## 事件驱动与高性能服务器

### 经典的服务器模型

同步式：一次只能处理一个请求，其他请求处于等待状态

每进程/每请求：为每个请求启动一个进程，不具备扩展性，系统资源有限

每线程/每请求：为每个请求启动一个线程，线程比进程轻量，每个线程占用一定内存，内存用光，会导致服务器缓慢

### node

事件驱动，**无需为每个请求创建额外的对应线程**，减少创建线程和销毁线程的开销，上下文切换的代价很低
